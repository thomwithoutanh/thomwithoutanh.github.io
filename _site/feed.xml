<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" hreflang="en" /><updated>2019-01-20T18:25:21+00:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Tom Walker</title><subtitle>Tom Walker's personal web page and blog
</subtitle><author><name>Tom Walker</name><email>&lt;hello@tomwalker.fyi&gt;</email></author><entry><title type="html">How can we make research used and useful?</title><link href="http://localhost:4000/2017/10/24/xxx/" rel="alternate" type="text/html" title="How can we make research used and useful?" /><published>2017-11-22T00:00:00+00:00</published><updated>2017-11-22T00:00:00+00:00</updated><id>http://localhost:4000/2017/10/24/mavc-communicating-research</id><content type="html" xml:base="http://localhost:4000/2017/10/24/xxx/">&lt;p&gt;When we summarised findings from Making All Voices Count’s research on how civil society organisations design and use technology, we found that they often struggle to set realistic expectations for their tech projects, do the right amount of user research, connect with the people they want to reach and adapt to unexpected changes (Read more on the programme’s findings on other themes, like &lt;a href=&quot;http://www.makingallvoicescount.org/blog/whats-needed-get-state-respond-citizens-part-problem/&quot;&gt;government responsiveness&lt;/a&gt; and &lt;a href=&quot;http://www.makingallvoicescount.org/publication/&quot;&gt;public participation&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;We wanted to try setting these messages out in a way that made them useful and easy to read. So we developed a microsite (a standalone, single-page website that displays a specialised set of content) to summarise the messages, and point readers directly to the evidence behind them: &lt;a href=&quot;https://researchfindings.tech/&quot;&gt;https://researchfindings.tech/&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;why-a-microsite&quot;&gt;Why a microsite?&lt;/h4&gt;

&lt;p&gt;Researchers have been asking &lt;a href=&quot;http://www.makingallvoicescount.org/blog/research-evidence-ethics-civic-tech-call-action/&quot;&gt;why existing research is not being used&lt;/a&gt; for some time now. Recently, there have been a series of calls to &lt;a href=&quot;https://methodicalsnark.org/2017/09/28/designing-civic-tech-research-at-scale-to-be-useful-why-methods-matter/&quot;&gt;understand what kind of evidence practitioners are actually likely to use&lt;/a&gt;, and to &lt;a href=&quot;https://medium.com/@laurawmcd/the-evidence-agenda-appealing-for-rationality-in-tech-for-social-change-41de18e4805a&quot;&gt;deal with the tech-for-social-change sector’s ‘weak culture of evidence and accountability’&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;These are key parts of the picture. But we think it’s also important to think about how that evidence is presented. When practitioners look for evidence, it may be hard for them to quickly work out what will be practically useful. The findings are there - they’re just mixed up with large blocks of text, or written in a style the practitioner isn’t used to.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We really need a focus on joining up lessons and making them digestible when designing anything that looks at technology and transparency in governance. - Amy O’Donnell, Oxfam GB&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Maybe it’s about the format of the evidence itself – rather than expecting busy practitioners to read long blocks of text, what about asking them to listen to experts talking about the research in their own words? In many places around the world, radio is the main way that people get information. Though obviously we couldn’t tap into radio stations or those networks, we wanted to try out providing research information in digestible soundbites.&lt;/p&gt;

&lt;p&gt;So, at Making All Voices Count’s final learning event “Appropriating technology for accountability’, we interviewed people from various countries and types of organisation: Michael (Miko) Canares from the Web Foundation’s &lt;a href=&quot;http://labs.webfoundation.org/&quot;&gt;Open Data Labs&lt;/a&gt;, Amy O’Donnell from &lt;a href=&quot;https://policy-practice.oxfam.org.uk/our-people/programme-implementation/amy-odonnell&quot;&gt;Oxfam GB&lt;/a&gt;, Koketso Moeti from &lt;a href=&quot;http://amandla.mobi/&quot;&gt;amandla.mobi&lt;/a&gt; in South Africa and the &lt;a href=&quot;https://lindaraftree.com/&quot;&gt;independent consultant&lt;/a&gt; Linda Raftree. Listen to the audio here:&lt;/p&gt;

&lt;h5 id=&quot;testing-how-practitioners-read-research-online&quot;&gt;Testing how practitioners read research online&lt;/h5&gt;

&lt;p&gt;Earlier in 2017, we at &lt;a href=&quot;https://www.theengineroom.org/&quot;&gt;The Engine Room&lt;/a&gt; had put this idea to the test by asking practitioners to read and engage with research we’d written ourselves.&lt;/p&gt;

&lt;p&gt;At the time, we were working on &lt;a href=&quot;https://alidade.tech/&quot;&gt;Alidade&lt;/a&gt;: an interactive tool that walks you through the process of choosing a technology tool, highlighting relevant resources and research findings along the way. We decided to run online walkthroughs with 10 project managers working on transparency and accountability initiatives in countries ranging from Nigeria to Indonesia.&lt;/p&gt;

&lt;p&gt;We asked them to read a one-page, online summary of the research, while sharing their screens with us so that we could see how they browsed. Our hopes were high: all of them had said they were interested in reading evidence about their work, and we’d tried to make the page as short as we could, split findings up into bullet points and highlighted key passages.&lt;/p&gt;

&lt;p&gt;Perhaps unsurprisingly, we were disappointed. Most only skimmed the research findings. Those with a stronger interest in research said that their eyes were drawn to the most skimmable parts: text in larger type, and the few graphics we’d included - even when they weren’t the most accurate reflection of the most important messages. Like all of us, they were dealing with an online information glut by trying to quickly assess if any of the information was relevant - and ignoring the rest.&lt;/p&gt;

&lt;p&gt;These observations won’t be news to anyone familiar with &lt;a href=&quot;https://www.newyorker.com/science/maria-konnikova/being-a-better-online-reader&quot;&gt;research into how we read online&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;People will often say that we don’t know where to find existing research. In a space like ours you’re exposed to so much of it, but you don’t make use of it. - Koketso Moeti&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;They also fit with the broader trend that we identified throughout Making All Voices Count’s research on the design of technology projects: that organisations weren’t doing enough research into their users’ needs. We asked Koketso, Linda, Miko and Amy why.&lt;/p&gt;

&lt;p&gt;So, the microsite we produced aims to highlight five simple messages, the most important evidence backing this up, and some ideas on how to do things differently. It’s designed to only show information that the reader is specifically interested in, reducing the amount of information to a minimum. Is this format a useful one for presenting evidence? We’ve been encouraged by some of the feedback we’ve already had:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://twitter.com/ppolitics&quot;&gt;&lt;img src=&quot;https://pbs.twimg.com/profile_images/740900955055640576/dMbl45tk_normal.jpg&quot; alt=&quot;Image&quot; /&gt;&lt;/a&gt; I like the accessible info display of &lt;a href=&quot;https://twitter.com/EngnRoom&quot;&gt;@EngnRoom&lt;/a&gt; findings on tech &amp;amp; international development NGO’s: &lt;a href=&quot;https://t.co/r4rygssGcP&quot;&gt;https://researchfindings.tech/ &lt;/a&gt; - via &lt;a href=&quot;https://twitter.com/Civicist&quot;&gt;@Civicist&lt;/a&gt;. &lt;a href=&quot;https://twitter.com/ppolitics/status/923551092205637632&quot;&gt;2:05 PM - Oct 26, 2017&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;https://twitter.com/RChandran1&quot;&gt;&lt;img src=&quot;https://pbs.twimg.com/profile_images/699427930150084608/OofjpErs_normal.jpg&quot; alt=&quot;Image&quot; /&gt;&lt;/a&gt; Great stuff &lt;a href=&quot;https://twitter.com/hashtag/AllVoicesCount?src=hash&quot;&gt;#AllVoicesCount&lt;/a&gt;:tech+civil society=a struggle. Love simple, clear “where’s the evidence?” &amp;amp; “so what?” &lt;a href=&quot;https://t.co/4fZIJ8OvXu&quot;&gt;https://researchfindings.tech/ &lt;/a&gt; &lt;a href=&quot;https://twitter.com/RChandran1/status/923567833619058688&quot;&gt;3:11 PM - Oct 26, 2017&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;However, we’re also keen to hear more views - is this a useful way of sharing evidence? What could we do differently?&lt;/p&gt;</content><author><name>Tom Walker</name></author><category term="technology, research" /><summary type="html">When we summarised findings from Making All Voices Count’s research on how civil society organisations design and use technology, we found that they often struggle to set realistic expectations for their tech projects, do the right amount of user research, connect with the people they want to reach and adapt to unexpected changes (Read more on the programme’s findings on other themes, like government responsiveness and public participation).</summary></entry><entry><title type="html">How to make sure that tech projects meet the brief</title><link href="http://localhost:4000/2017/10/22/xxx/" rel="alternate" type="text/html" title="How to make sure that tech projects meet the brief" /><published>2017-10-22T00:00:00+01:00</published><updated>2017-10-22T00:00:00+01:00</updated><id>http://localhost:4000/2017/10/22/mavc-research-review</id><content type="html" xml:base="http://localhost:4000/2017/10/22/xxx/">&lt;p&gt;Over the last four years, Making All Voices Count (MAVC) has published about 70 research reports, practice papers and journal articles, investigating tech-enabled projects that aim to amplify citizens’ voices and encourage government to respond to them.&lt;/p&gt;

&lt;p&gt;They cover a huge range of kinds of organisation and types of technology, ranging from broad assessments of 38 organisations’ tech selection processes to in-depth accounts of how one Ghanaian organisation implemented an interactive voice response survey.&lt;/p&gt;

&lt;p&gt;This research holds huge potential for practitioners working in this space. So, as the programme draws to a close, my colleagues at The Engine Room and I have been reading through these research pieces and looking for common threads.&lt;/p&gt;

&lt;h4 id=&quot;making-tech-effective--building-on-what-we-already-know&quot;&gt;Making tech effective – building on what we already know&lt;/h4&gt;

&lt;p&gt;One thread stands out: the way that organisations choose and use technology, and how this affects their projects. The overall picture painted by the research is clear: many organisations are struggling to use technology in a way that they feel makes their projects more effective.&lt;/p&gt;

&lt;p&gt;This may come as no surprise. (&lt;a href=&quot;http://www.makingallvoicescount.org/blog/research-evidence-ethics-civic-tech-call-action/&quot;&gt;Researchers have been saying similar things&lt;/a&gt; for some time now.) The factors behind it are not entirely new, either: earlier research has repeatedly cited the need for &lt;a href=&quot;https://www.ids.ac.uk/publication/learning-study-on-the-users-in-technology-for-transparency-and-accountability-initiatives-assumptions-and-realities&quot;&gt;stronger understandings of what users need&lt;/a&gt; and &lt;a href=&quot;http://www.transparency-initiative.org/uncategorized/513/global-mapping-of-technology-for-transparency-and-accountability/&quot;&gt;deeper collaboration&lt;/a&gt; with a wider range of groups that projects want to influence.&lt;/p&gt;

&lt;p&gt;But, taken together, Making All Voices Count’s research outputs add considerable weight to the evidence behind these messages – and should make them even harder to ignore. What’s more, they point to practical steps that projects are already taking to address these challenges.&lt;/p&gt;

&lt;h4 id=&quot;thoughts-on-when-tech-works-from-the-horses-mouth&quot;&gt;Thoughts on when tech works, from the horse’s mouth&lt;/h4&gt;

&lt;p&gt;Many of the research pieces concentrate on asking organisations how they felt their project had gone, and what role tech played.&lt;/p&gt;

&lt;p&gt;This is significant partly because it’s relatively rare. In a sector that’s often accused of trying to run before it can walk, projects don’t often get the chance to step back and reflect – especially in a way that researchers can compare across multiple projects. Making All Voices Count actively encouraged this reflection throughout the programme, and will carry on doing so at its final learning event this week.&lt;/p&gt;

&lt;p&gt;But this research method was also interesting for another reason: it may have encouraged organisations to be candid.&lt;/p&gt;

&lt;p&gt;Researchers often asked organisations to describe their project’s progress from beginning to end, or think back to a specific moment that was important for their project. Many participants were given anonymity, or the space to explain their project’s context in detail, and as a result, had more freedom to describe how they had really used tech.&lt;/p&gt;

&lt;p&gt;Many responded by being, as one report put it, “unexpectedly open and often self-critical” about their own work. As such, the research frequently gives valuable insights into the unvarnished reality of designing and implementing technology in transparency and accountability initiatives.&lt;/p&gt;

&lt;h4 id=&quot;many-organisations-are-disillusioned-with-the-contribution-technology-had-made-to-their-project&quot;&gt;Many organisations are disillusioned with the contribution technology had made to their project&lt;/h4&gt;

&lt;p&gt;As we read, we repeatedly encountered one overriding sentiment: disappointment. All too often, organisations told researchers that they were dissatisfied with what tech had been able to do for them.&lt;/p&gt;

&lt;p&gt;For example, of the seven MAVC-funded projects that &lt;a href=&quot;http://www.makingallvoicescount.org/publication/ict-facilitated-accountability-engagement-health-systems-review-making-voices-count-mhealth-accountability-projects/&quot;&gt;used information and communication technologies (ICTs) to promote accountability in health systems&lt;/a&gt;, four experienced: “disconnects between their expectations of what the technology could do, what it actually did, and the implications for accountability.” Meanwhile, in Kenya and South Africa, &lt;a href=&quot;https://alidade.tech/page/research&quot;&gt;more than 75% of the 38 transparency and accountability initiatives&lt;/a&gt; interviewed said that they weren’t happy with the technology tools they’d chosen. Many had already moved on to a new tool by the time that the researchers spoke to them.&lt;/p&gt;

&lt;p&gt;In several cases, researchers linked this to organisations’ limited knowledge of the people they wanted to use the tools. Only 15 of the 38 Kenyan and South African initiatives &lt;a href=&quot;https://alidade.tech/page/research&quot;&gt;did any user research before choosing a technology tool&lt;/a&gt;. More than half of the total then said that their tool had not been used in the way they had hoped.&lt;/p&gt;

&lt;p&gt;Elsewhere, it was attributed to more technical issues. In Kenya, &lt;a href=&quot;http://www.makingallvoicescount.org/publication/digital-development-differently-lessons-adaptive-management-technology-governance-initiatives-kenya/&quot;&gt;59% of the 24 projects interviewed by researchers&lt;/a&gt; said that a lack of technical knowledge was a barrier for their projects: a finding echoed by &lt;a href=&quot;http://www.makingallvoicescount.org/publication/ict-facilitated-accountability-engagement-health-systems-review-making-voices-count-mhealth-accountability-projects/&quot;&gt;Hyrnick and Waldman’s mHealth research&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;but-we-now-have-more-evidence-on-whats-helping-organisations-make-better-decisions&quot;&gt;But we now have more evidence on what’s helping organisations make better decisions&lt;/h4&gt;

&lt;p&gt;When user research did take place, in-depth practice papers showed the profound difference that it made to projects. For example, the &lt;a href=&quot;http://www.makingallvoicescount.org/publication/lessons-yowzits-pracitioner-research-learning-process/&quot;&gt;South African organisation Yowzit used user research to discover that its users would only find their citizen participation platform convenient&lt;/a&gt; if they spoke English, were digitally literate and already used similar ratings platforms. This helped them to target their work with a revised, tighter focus.&lt;/p&gt;

&lt;p&gt;Researchers found that although organisations had to invest time up-front in doing thorough user research, it could actually save them effort in the long run. In South Africa, for example, &lt;a href=&quot;http://www.makingallvoicescount.org/publication/giving-voice-clients-post-rape-services-building-piloting-feedback-mechanism-tshwane/&quot;&gt;the Foundation for Professional Development (FPD)’s user research&lt;/a&gt; showed them that they needed to focus on building an app focused on clients’ needs, rather than the more ambitious programme they had planned. Others found effective ways of combining offline and online content, as with &lt;a href=&quot;http://www.makingallvoicescount.org/publication/open-mapping-ground-learning-map-kibera/&quot;&gt;Map Kibera’s community engagement work&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The research re-emphasised that projects that use tech depend on strong relationships as well as well-designed technology products. For example, Tiago Peixoto and Jonathan Fox found, projects using technology to increase government responsiveness are &lt;a href=&quot;http://www.makingallvoicescount.org/publication/ict-enabled-citizen-voice-lead-government-responsiveness/&quot;&gt;more likely to suceed when governments already want to get (and act on) feedback&lt;/a&gt;from citizens. Meanwhile, the multi-country assessment of mHealth initiatives suggested that &lt;a href=&quot;http://www.makingallvoicescount.org/publication/ict-facilitated-accountability-engagement-health-systems-review-making-voices-count-mhealth-accountability-projects/&quot;&gt;projects were more likely to report success when they had strong, long-standing connections&lt;/a&gt; with the the people or government actors they were working with.&lt;/p&gt;

&lt;h4 id=&quot;changing-course-during-a-project-the-toughest-challenge-of-all&quot;&gt;Changing course during a project: the toughest challenge of all&lt;/h4&gt;

&lt;p&gt;Finally, research indicated that organisations need to be able to do more than this. They also needed to be able to research &lt;a href=&quot;http://www.saiia.org.za/policy-briefings/why-isn-t-tech-for-accountability-working-in-africa&quot;&gt;all three aspects required for a successful tech project&lt;/a&gt;: the accountability problem they were trying to solve; the people they wanted to reach; and the tech options available. Then, they needed to put what they learned into practice, by adapting to what they found out during the process. In Kenya and South Africa, &lt;a href=&quot;https://alidade.tech/page/research&quot;&gt;those of the 38 organisations that trialled their tools with their users&lt;/a&gt; were by far the most likely to be happy with their eventual choice.&lt;/p&gt;

&lt;p&gt;This challenge proved to be beyond many of the organisations that took part in the research. Looking back, &lt;a href=&quot;http://www.makingallvoicescount.org/publication/digital-development-differently-lessons-adaptive-management-technology-governance-initiatives-kenya/&quot;&gt;79% of the 24 Kenyan organisations interviewed said that “adapting to context mattered a lot for the project&lt;/a&gt;,” but were unable to adapt fully themselves. For projects to be genuinely adaptive, they need to be supported with flexible funding and tools for transparent communication with funders. The &lt;a href=&quot;http://www.makingallvoicescount.org/publication/giving-voice-clients-post-rape-services-building-piloting-feedback-mechanism-tshwane/&quot;&gt;FPD&lt;/a&gt; and &lt;a href=&quot;http://www.makingallvoicescount.org/publication/lessons-yowzits-pracitioner-research-learning-process/&quot;&gt;Yowzit&lt;/a&gt; practice papers provide examples of this approach in action, and we’re looking forward to discussing what this means&lt;/p&gt;

&lt;h4 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h4&gt;

&lt;p&gt;The research that’s come out of this four-year programme is a valuable contribution to our understanding of how tech projects working in transparency and accountability can be most effective. Being given time to reflect and critically assess your own work, doesn’t come around that often, and we’re grateful to Making All Voices Count for providing many such opportunities.&lt;/p&gt;

&lt;p&gt;If the research findings are taken as practical lessons that influence future work by practitioners and civil society more broadly, they will have a better chance of success. The next challenges are for practitioners to understand which findings could influence the way they design their next project, and for funders and intermediaries to keep supporting the kind of networks that allow these findings to spread widely.&lt;/p&gt;</content><author><name>Tom Walker</name></author><category term="technology, research" /><summary type="html">Over the last four years, Making All Voices Count (MAVC) has published about 70 research reports, practice papers and journal articles, investigating tech-enabled projects that aim to amplify citizens’ voices and encourage government to respond to them.</summary></entry></feed>