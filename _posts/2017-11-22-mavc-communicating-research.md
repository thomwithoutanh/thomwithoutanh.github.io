---
title: How can we make research used and useful?
teaser: "xxx"
author: Tom Walker
layout: post
permalink: /2017/10/24/xxx/
categories:
  - communications
tags:
  - technology, research
---

When we summarised findings from Making All Voices Count’s research on how civil society organisations design and use technology, we found that they often struggle to set realistic expectations for their tech projects, do the right amount of user research, connect with the people they want to reach and adapt to unexpected changes (Read more on the programme’s findings on other themes, like [government responsiveness](http://www.makingallvoicescount.org/blog/whats-needed-get-state-respond-citizens-part-problem/) and [public participation](http://www.makingallvoicescount.org/publication/)).

We wanted to try setting these messages out in a way that made them useful and easy to read. So we developed a microsite (a standalone, single-page website that displays a specialised set of content) to summarise the messages, and point readers directly to the evidence behind them: [https://researchfindings.tech/](https://researchfindings.tech/)

#### Why a microsite?

Researchers have been asking [why existing research is not being used](http://www.makingallvoicescount.org/blog/research-evidence-ethics-civic-tech-call-action/) for some time now. Recently, there have been a series of calls to [understand what kind of evidence practitioners are actually likely to use](https://methodicalsnark.org/2017/09/28/designing-civic-tech-research-at-scale-to-be-useful-why-methods-matter/), and to [deal with the tech-for-social-change sector’s ‘weak culture of evidence and accountability’](https://medium.com/@laurawmcd/the-evidence-agenda-appealing-for-rationality-in-tech-for-social-change-41de18e4805a).

These are key parts of the picture. But we think it’s also important to think about how that evidence is presented. When practitioners look for evidence, it may be hard for them to quickly work out what will be practically useful. The findings are there - they’re just mixed up with large blocks of text, or written in a style the practitioner isn’t used to.

> We really need a focus on joining up lessons and making them digestible when designing anything that looks at technology and transparency in governance. - Amy O’Donnell, Oxfam GB

Maybe it’s about the format of the evidence itself – rather than expecting busy practitioners to read long blocks of text, what about asking them to listen to experts talking about the research in their own words? In many places around the world, radio is the main way that people get information. Though obviously we couldn’t tap into radio stations or those networks, we wanted to try out providing research information in digestible soundbites.

So, at Making All Voices Count's final learning event "Appropriating technology for accountability', we interviewed people from various countries and types of organisation: Michael (Miko) Canares from the Web Foundation’s [Open Data Labs](http://labs.webfoundation.org/), Amy O'Donnell from [Oxfam GB](https://policy-practice.oxfam.org.uk/our-people/programme-implementation/amy-odonnell), Koketso Moeti from [amandla.mobi](http://amandla.mobi/) in South Africa and the [independent consultant](https://lindaraftree.com/) Linda Raftree. Listen to the audio here:

##### Testing how practitioners read research online

Earlier in 2017, we at [The Engine Room](https://www.theengineroom.org/) had put this idea to the test by asking practitioners to read and engage with research we’d written ourselves.

At the time, we were working on [Alidade](https://alidade.tech/): an interactive tool that walks you through the process of choosing a technology tool, highlighting relevant resources and research findings along the way. We decided to run online walkthroughs with 10 project managers working on transparency and accountability initiatives in countries ranging from Nigeria to Indonesia.

We asked them to read a one-page, online summary of the research, while sharing their screens with us so that we could see how they browsed. Our hopes were high: all of them had said they were interested in reading evidence about their work, and we'd tried to make the page as short as we could, split findings up into bullet points and highlighted key passages.

Perhaps unsurprisingly, we were disappointed. Most only skimmed the research findings. Those with a stronger interest in research said that their eyes were drawn to the most skimmable parts: text in larger type, and the few graphics we'd included - even when they weren't the most accurate reflection of the most important messages. Like all of us, they were dealing with an online information glut by trying to quickly assess if any of the information was relevant - and ignoring the rest.

These observations won't be news to anyone familiar with [research into how we read online](https://www.newyorker.com/science/maria-konnikova/being-a-better-online-reader).

> People will often say that we don’t know where to find existing research. In a space like ours you’re exposed to so much of it, but you don’t make use of it. - Koketso Moeti

They also fit with the broader trend that we identified throughout Making All Voices Count’s research on the design of technology projects: that organisations weren’t doing enough research into their users’ needs. We asked Koketso, Linda, Miko and Amy why.

So, the microsite we produced aims to highlight five simple messages, the most important evidence backing this up, and some ideas on how to do things differently. It’s designed to only show information that the reader is specifically interested in, reducing the amount of information to a minimum. Is this format a useful one for presenting evidence? We’ve been encouraged by some of the feedback we’ve already had:

> [![Image](https://pbs.twimg.com/profile_images/740900955055640576/dMbl45tk_normal.jpg)](https://twitter.com/ppolitics) I like the accessible info display of [@EngnRoom](https://twitter.com/EngnRoom) findings on tech & international development NGO's: [https://researchfindings.tech/ ](https://t.co/r4rygssGcP) - via [@Civicist](https://twitter.com/Civicist). [2:05 PM - Oct 26, 2017](https://twitter.com/ppolitics/status/923551092205637632)

> [![Image](https://pbs.twimg.com/profile_images/699427930150084608/OofjpErs_normal.jpg)](https://twitter.com/RChandran1) Great stuff [#AllVoicesCount](https://twitter.com/hashtag/AllVoicesCount?src=hash):tech+civil society=a struggle. Love simple, clear "where's the evidence?" & "so what?" [https://researchfindings.tech/ ](https://t.co/4fZIJ8OvXu) [3:11 PM - Oct 26, 2017](https://twitter.com/RChandran1/status/923567833619058688)

However, we’re also keen to hear more views - is this a useful way of sharing evidence? What could we do differently?
